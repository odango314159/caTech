# -*- coding: utf-8 -*-
"""BERTmodelbaseline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MeGXklLnJcciwRplxphJKPwRKV2VzP-x
"""

!pip install transformers
!pip install fugashi
!pip install ipadic
!apt install aptitude
!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y
!pip install mecab-python3
!pip install unidic
!python -m unidic download
import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt
import json
from tqdm import tqdm
from pathlib import Path
import torch
from torch import nn
from torch.utils.data import Dataset,DataLoader
import transformers
from transformers import AutoModel
from transformers import AutoTokenizer
from torch.optim import Adam
import MeCab

from google.colab import drive
drive.mount('/content/drive')

data_dir = './drive/MyDrive/section4/chABSA-dataset'
data_path = Path(data_dir)

path_list = []
for file_path in data_path.iterdir():
  path_list.append(str(file_path))
path_list[:5]

def create_rating(sentences):
    rating = []
    for obj in sentences:
        s = obj["sentence"]
        op = obj["opinions"]
        porarity = 0
        for o in op:
            p = o["polarity"]
            if p == "positive":
                porarity += 1
            elif p == "negative":
                porarity -= 1
        if porarity !=0 :
            rating.append((porarity, s))
    return rating

!rm -r './drive/MyDrive/section4/chABSA-dataset/chABSA-dataset'

rating = []
for file_path in path_list:
  with open(file_path) as f:
    j = json.load(f)
  sentences = j["sentences"]
  rating += create_rating(sentences)

negative_list = []
positive_list = []

for i in rating:
  if i[0] > 0:
    positive_list.append(i[1])
  else:
    negative_list.append(i[1])

df_neg = pd.DataFrame({'text':negative_list})
df_pos = pd.DataFrame({'text':positive_list})

df_neg['label'] = 0
df_pos['label'] = 1

df = pd.concat([df_neg,df_pos],axis=0,ignore_index=True)
df = df.sample(frac=1).reset_index(drop=True)
df = df.rename(columns={'index': 'Id'})

"""後で試すために10サンプルだけ取り出してテストデータとする。"""

test_df = df.tail(10)

"""`モデルの作成"""

train_text = df["text"].tolist()
train_label = (df["label"]-1).tolist()

df["len"] = df['text'].str.len()

df["len"].max()

df.loc[df["len"] == 401,"text"]

train_text[:5]

t = MeCab.Tagger("-O wakati")
sentence = train_text[0]
print(t.parse(sentence))
print(type(t.parse(sentence)))

df["text"] =df["text"].apply(t.parse)

checkpoint = 'cl-tohoku/bert-base-japanese-whole-word-masking'
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

encodings = tokenizer(train_text,padding="max_length",max_length=128,truncation=True)
input_ids = encodings['input_ids']
attention_mask = encodings['attention_mask']

encodings.keys()

plt.hist(np.array(df["len"]))
plt.show()

from sklearn.model_selection import train_test_split
data  = df[["text","label"]]
train_data,test_data = train_test_split(data,test_size=0.2)

data["text"].tolist()[0]

MAX_LEN = 256
class MyDataset(Dataset):
  def __init__(self,data,tokenizer):
    self.data = data
    self.tokenizer = AutoTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')
  def __len__(self):
    return len(self.data)
  def __getitem__(self,idx):
    text = self.data["text"].tolist()[idx]
    label = self.data["label"].tolist()[idx]
    label = torch.tensor(label,dtype=torch.int64)
    encodings = self.tokenizer(
        text,padding="max_length",max_length=MAX_LEN,truncation=True
    )

    input_ids = torch.tensor(
        encodings["input_ids"],dtype=torch.long
    )
    
    attention_mask = torch.tensor(
        encodings["attention_mask"],dtype=torch.long
    )

    token_type_ids = torch.tensor(
        encodings["token_type_ids"],dtype=torch.long
    )

    return input_ids,attention_mask,token_type_ids,label

train_data = MyDataset(train_data,tokenizer)
test_data = MyDataset(test_data,tokenizer)

train_loader = DataLoader(train_data,batch_size=16,shuffle=True,drop_last=True)
test_loader = DataLoader(train_data,batch_size=16,shuffle=True,drop_last=True)

class BERTmodel(nn.Module):
  def __init__(self):
    super(BERTmodel,self).__init__()
    self.bert = AutoModel.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')
    self.linear1 = nn.Linear(in_features=768,out_features=256)
    self.linear2 = nn.Linear(256,64)
    self.linear3 = nn.Linear(64,2)
    self.relu = nn.ReLU(inplace=True)
    self.softmax = nn.functional.softmax
  def forward(self,input_ids,attention_mask,token_type_ids):
    x = self.bert(
        input_ids = input_ids,
        attention_mask = attention_mask,
        token_type_ids = token_type_ids
    )
    x = x.pooler_output
    ###こっからヘッダー分類器
    x = self.linear1(x)
    x = self.relu(x)
    x = self.linear2(x)
    x = self.relu(x)
    x = self.linear3(x)
    output = self.softmax(x,dim=1)
    return output

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = BERTmodel().to(device)
optimizer = Adam(model.parameters(),lr = 1e-5)
criterion = nn.CrossEntropyLoss()
epoch = 10
for i in range(epoch):
  print('---------------------')
  print("Epoch:{}/{}".format(i+1,epoch))

  train_loss = 0
  train_accuracy = 0
  test_loss = 0
  test_accuracy = 0

  model.train()

  for batch in tqdm(train_loader):
    optimizer.zero_grad()
    input_ids = batch[0].to(device)
    attention_mask = batch[1].to(device)
    token_type_ids = batch[2].to(device)
    
    label = batch[3].to(device)
    pred = model(input_ids,attention_mask,token_type_ids)
    loss = criterion(pred,label)
    loss.backward()
    optimizer.step()
    train_loss += loss.item()
    pred_label = torch.max(pred,1)[1]
    train_accuracy += torch.sum(pred_label.view(-1,16)==label).item()/len(label)
  train_loss = train_loss/len(train_loader)
  train_accuracy = train_accuracy/len(train_loader)
  print("train_loss = {}".format(train_loss))
  print("train_acc = {}".format(train_accuracy))
  model.eval()
  with torch.no_grad():
    for batch in tqdm(test_loader):
      input_ids = batch[0].to(device)
      attention_mask = batch[1].to(device)
      token_type_ids = batch[2].to(device)
      
      label = batch[3].to(device)
      pred = model(input_ids,attention_mask,token_type_ids)
      loss = criterion(pred,label)
      test_loss += loss.item()
      pred_label = torch.max(pred,1)[1]
      test_accuracy += torch.sum(pred_label.view(-1,16)==label).item()/len(label)
  test_loss = test_loss/len(test_loader)
  test_accuracy = test_accuracy/len(test_loader)
  print("test_loss = {}".format(test_loss))
  print("test_acc = {}".format(test_accuracy))

valid_data = pd.DataFrame()
valid_data["text"] = np.array(["売り上げ収益は2兆6367億円と、前年同期比931億円の増収です。この中には、事業再編による影響が含まれており、これを除くと1266億円と5.1%の増収となりました。主にテクノロジーソリューションでSI/サービスを中心として増収となりました。"])
valid_data["label"] = np.array([2])
valid_data.head()

valid_data = MyDataset(valid_data,tokenizer)
valid_loader = DataLoader(valid_data,batch_size=1)

device = torch.device('cpu')
def predict(text):
  """
  text = str
  """
  valid_data = pd.DataFrame()
  valid_data["text"] = np.array([text])
  valid_data["label"] = np.array([2]) ###これは仮に決めた値。0か1に更新される
  valid_data = MyDataset(valid_data,tokenizer)
  valid_loader = DataLoader(valid_data,batch_size=1)
  with torch.no_grad():
    for batch in valid_loader:
      input_ids = batch[0].to(device)
      attention_mask = batch[1].to(device)
      token_type_ids = batch[2].to(device)
      output = model(input_ids,attention_mask,token_type_ids)
      label = ["negative","positive"][int(torch.max(output,1)[1])]
      score = float(torch.max(output,1)[0])
      return label,score

label,score = predict("親会社の所有者に所属する四半期利益は1227億円と前年同期比115億円の減益となりました。前年同期に北米事業再編に伴う税金費用の減少効果が含まれていた影響です")

print("label of prediction is {}".format(label))
print("score of prediction is {}".format(score))

import torch
torch.save(model.to('cpu').state_dict(),'./drive/MyDrive/BERTparam.pth')

model = BERTmodel()
model.load_state_dict(torch.load('./drive/MyDrive/BERTmodel.pth'))

net = model.to(device)
with torch.no_grad():
  for batch in valid_loader:
    input_ids = batch[0].to(device)
    attention_mask = batch[1].to(device)
    token_type_ids = batch[2].to(device)
    output = net(input_ids,attention_mask,token_type_ids)
    label = ["negative","positive"][int(torch.max(output,1)[1])]
    score = float(torch.max(output,1)[0])
    print("label of prediction is {}".format(label))
    print("score of prediction is {}".format(score))

