{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNrX98RUDaYuPlJ4wEGwJeI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/odango314159/caTech/blob/main/LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install accelerate"
      ],
      "metadata": {
        "id": "SsE8IwG7pMhM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "-aaF4JGnr3-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "P92vyj7DoWLF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM,AutoTokenizer\n",
        "from accelerate import Accelerator\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"cyberagent/open-calm-small\",low_cpu_mem_usage=False,torch_dtype=torch.float16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cyberagent/open-calm-small\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "\n",
        "dolly_ja = datasets.load_dataset(\"kunishou/databricks-dolly-15k-ja\")"
      ],
      "metadata": {
        "id": "8uSKbQ0VpIIJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dolly_ja['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uI7VabksKJv",
        "outputId": "ff450195-ebf7-4b0f-fc57-2e4686572f30"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'category': 'closed_qa',\n",
              " 'index': '0',\n",
              " 'instruction': 'ヴァージン・オーストラリア航空はいつから運航を開始したのですか？',\n",
              " 'output': 'ヴァージン・オーストラリア航空は、2000年8月31日にヴァージン・ブルー航空として、2機の航空機で単一路線の運航を開始しました。',\n",
              " 'input': 'ヴァージン・オーストラリア航空（Virgin Australia Airlines Pty Ltd）はオーストラリアを拠点とするヴァージン・ブランドを冠する最大の船団規模を持つ航空会社です。2000年8月31日に、ヴァージン・ブルー空港として、2機の航空機、1つの空路を運行してサービスを開始しました。2001年9月のアンセット・オーストラリア空港の崩壊後、オーストラリアの国内市場で急速に地位を確立しました。その後はブリスベン、メルボルン、シドニーをハブとして、オーストラリア国内の32都市に直接乗り入れるまでに成長しました。'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dolly_ja = list(dolly_ja['train'])"
      ],
      "metadata": {
        "id": "AqFflpx_sTgW"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_DICT = {\n",
        "    \"prompt_input\":(\n",
        "        \"以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。\"\n",
        "        \"要求を適切に満たす応答を書きなさい。\\n\\n\"\n",
        "        \"### 指示:\\n{instruction}\\n\\n### 入力:{input}\\n\\n### 応答:\"\n",
        "    ),\n",
        "    \"prompt_no_input\":(\n",
        "        \"以下は、タスクを説明する指示です。\"\n",
        "        \"要求を適切に満たす応答を書きなさい。\\n\\n\"\n",
        "        \"### 指示:\\n{instruction}\\n\\n### 応答:\"\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "jpsssBqLs_xD"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JD59YhcCQXAy"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.deprecated.tapex.tokenization_tapex import json\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class InstructDataset(Dataset):\n",
        "  def __init__(self,json_list,tokenizer,ignore_index=-100):\n",
        "    ###tokenizerの定義\n",
        "    self.tokenizer = tokenizer\n",
        "    ###\n",
        "    self.ignore_index = ignore_index\n",
        "    self.json_list = json_list\n",
        "    self.features = []\n",
        "\n",
        "    for j in tqdm(json_list):\n",
        "      if 'input' in j:\n",
        "        ###取り出してきたjsonファイルに'input'キーが存在した時\n",
        "        ###source_textをPROMPT_DICTの'prompt_input(文脈アリ)にして\n",
        "        \"\"\"\n",
        "\n",
        "        (\n",
        "        \"以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。\"\n",
        "        \"要求を適切に満たす応答を書きなさい。\\n\\n\"\n",
        "        \"### 指示:\\n{instruction}\\n\\n### 入力:{input}\\n\\n### 応答:\"\n",
        "    )\n",
        "\n",
        "\n",
        "       instructionにjsonファイルのinstruction,inputにjsonファイルのinputを代入した値にして\n",
        "       応答:までを問題文とする。\n",
        "        \"\"\"\n",
        "        source_text = PROMPT_DICT['prompt_input'].format_map(j)\n",
        "      else:\n",
        "        source_text = PROMPT_DICT['prompt_no_input'].format_map(j)\n",
        "\n",
        "      example_text = source_text + j['output'] + self.tokenizer.eos_token\n",
        "\n",
        "      source_tokenized = self.tokenizer(\n",
        "          source_text,\n",
        "          padding = 'longest',\n",
        "          truncation = True,\n",
        "          max_length = 512,\n",
        "          return_length = True,\n",
        "          return_tensors = 'pt'\n",
        "      )\n",
        "\n",
        "      example_tokenized = self.tokenizer(\n",
        "          example_text,\n",
        "          padding = 'longest',\n",
        "          truncation = True,\n",
        "          max_length = 512,\n",
        "          return_tensors = 'pt'\n",
        "      )\n",
        "\n",
        "      input_ids = example_tokenized['input_ids'][0]\n",
        "\n",
        "      labels = copy.deepcopy(input_ids)\n",
        "\n",
        "      source_len = source_tokenized['length'][0]\n",
        "\n",
        "      labels[:source_len] = self.ignore_index\n",
        "\n",
        "      self.features.append(\n",
        "          {\n",
        "              'input_ids':input_ids,\n",
        "              'labels':labels\n",
        "          }\n",
        "      )\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "  def __getitem__(self,idx):\n",
        "    return self.features[idx]"
      ],
      "metadata": {
        "id": "DA82sWT-uFTV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = InstructDataset(dolly_ja,tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcAFpGeUyvje",
        "outputId": "a3667667-f610-4bd4-9619-cc0c58dfa4ac"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15015/15015 [00:29<00:00, 508.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class InstructCollator():\n",
        "  def __init__(self,tokenizer,ignore_index=-100):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.ignore_index = -100\n",
        "\n",
        "  def __call__(self,examples):\n",
        "    input_batch = []\n",
        "    label_batch = []\n",
        "    for example in examples:\n",
        "      input_batch.append(example['input_ids'])\n",
        "      label_batch.append(example['labels'])\n",
        "\n",
        "    input_ids = pad_sequence(\n",
        "        input_batch,batch_first=True,padding_value=self.tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "    labels = pad_sequence(\n",
        "        label_batch,batch_first=True,padding_value=self.ignore_index\n",
        "    )\n",
        "\n",
        "    attention_mask = input_ids.ne(self.tokenizer.pad_token_id)\n",
        "\n",
        "    return {\n",
        "        'input_ids':input_ids,\n",
        "        'labels':labels,\n",
        "        'attention_mask':attention_mask\n",
        "    }"
      ],
      "metadata": {
        "id": "Sdtl5U-Py0Lm"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "collator = InstructCollator(tokenizer)\n",
        "loader = DataLoader(train_dataset,collate_fn=collator,batch_size=8,shuffle=True)\n",
        "\n",
        "batch = next(iter(loader))\n",
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h32aZycUQNg",
        "outputId": "0277fa9f-704e-4f82-84d4-e553980e1a74"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[24284,   245, 14946,  ...,     1,     1,     1],\n",
              "         [24284,   245, 14946,  ...,     1,     1,     1],\n",
              "         [24284,   245, 14946,  ...,     1,     1,     1],\n",
              "         ...,\n",
              "         [24284,   245, 14946,  ...,     1,     1,     1],\n",
              "         [24284,   245, 14946,  ...,     1,     1,     1],\n",
              "         [24284,   245, 14946,  ...,     1,     1,     1]]),\n",
              " 'labels': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
              "         [-100, -100, -100,  ..., -100, -100, -100],\n",
              "         [-100, -100, -100,  ..., -100, -100, -100],\n",
              "         ...,\n",
              "         [-100, -100, -100,  ..., -100, -100, -100],\n",
              "         [-100, -100, -100,  ..., -100, -100, -100],\n",
              "         [-100, -100, -100,  ..., -100, -100, -100]]),\n",
              " 'attention_mask': tensor([[ True,  True,  True,  ..., False, False, False],\n",
              "         [ True,  True,  True,  ..., False, False, False],\n",
              "         [ True,  True,  True,  ..., False, False, False],\n",
              "         ...,\n",
              "         [ True,  True,  True,  ..., False, False, False],\n",
              "         [ True,  True,  True,  ..., False, False, False],\n",
              "         [ True,  True,  True,  ..., False, False, False]])}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "  if param.ndim ==1:\n",
        "    param.data = param.data.to(torch.float32)"
      ],
      "metadata": {
        "id": "CBbMITd5LD6t"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False # モデルをフリーズ\n",
        "    if param.ndim == 1:\n",
        "        # 安定のためにレイヤーノルムをfp32にキャスト\n",
        "        param.data = param.data.to(torch.float32)\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model.enable_input_require_grads()\n",
        "\n",
        "class CastOutputToFloat(nn.Sequential):\n",
        "    def forward(self, x): return super().forward(x).to(torch.float32)\n",
        "model.embed_out = CastOutputToFloat(model.embed_out)"
      ],
      "metadata": {
        "id": "_K_5denoUXes"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.gpt_neox.layers[0].attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBUdYx_EUY92",
        "outputId": "5bc040de-d511-4969-c0f4-46ff3d16c4f4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXAttention(\n",
              "  (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "  (query_key_value): Linear(in_features=768, out_features=2304, bias=True)\n",
              "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import get_peft_model,LoraConfig,TaskType"
      ],
      "metadata": {
        "id": "eDZ_TDYJUez-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha = 32,\n",
        "    target_modules=[\"query_key_value\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    fan_in_fan_out = False,\n",
        "    task_type = TaskType.CAUSAL_LM\n",
        ")\n",
        "\n",
        "model = get_peft_model(model,lora_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DUC5DsrVd85",
        "outputId": "ff92330e-ab3c-4081-f167-84af09a5a12e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 294,912 || all params: 165,370,368 || trainable%: 0.1783342466771314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "        output_dir='./output',\n",
        "        save_total_limit=1,\n",
        "        per_device_train_batch_size=8,\n",
        "        num_train_epochs=1,\n",
        "        remove_unused_columns=False,\n",
        "        logging_steps=20,\n",
        "        fp16=True,\n",
        "        dataloader_num_workers=16,\n",
        "        report_to=\"none\",\n",
        ")"
      ],
      "metadata": {
        "id": "fTbQrFf-Xmfl"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "        model=model,\n",
        "        data_collator=collator,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "    )"
      ],
      "metadata": {
        "id": "z_Pb4Y_8dExb"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lhyZBhSodD1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache = False\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "3tzIfR0GaFhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"./output\")"
      ],
      "metadata": {
        "id": "F8pPZ-25f9tc"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8nv2luChoaYC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}